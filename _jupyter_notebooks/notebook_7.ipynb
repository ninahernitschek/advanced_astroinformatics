{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supvervised Classification, Data Processing Pipelines\n",
    "\n",
    "**Advanced Astroinformatics Student Project**\n",
    "\n",
    "*N. Hernitschek, 2022*\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## Contents\n",
    "* [Recap, Questions](#first-bullet)\n",
    "* [Supervised Classification - Binary Classifiers](#second-bullet)\n",
    "* [Supervised Classification - Multiclass Classifiers](#third-bullet)\n",
    "* [Data Processing Pipelines](#second-bullet)\n",
    "* [Summary](#fifth-bullet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap, Questions <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "Time for questions!\n",
    "\n",
    "Your **tasks until this week** were:\n",
    "\n",
    "Use a the k-means algorithm on the three TESS feature data sets, including making diagnostic plots.\n",
    "\n",
    "Try to interpret your results.\n",
    "How do your results differ from the a) _TESS_lightcurves_outliercleaned, b) _TESS_lightcurves_median_after_detrended, c) _TESS_lightcurves_raw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised Classification - Binary Classifiers <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "\n",
    "Random forest classifiers generate decision trees from bootstrap samples. A interesting aspect of random forests is that the features on which to generate the tree are selected at random from the full set of features in the data (the number of features selected per split level is typically the square root of the total number of attributes). The final classification from the random forest is based on the averaging of the classifications of each of the individual decision trees. So, you can literally give it anything (including attributes that you might not otherwise think would be useful for classification).\n",
    "\n",
    "Random forests help to overcome some of the limitations of decision trees.\n",
    "\n",
    "As before, cross-validation can be used to determine the optimal depth. Generally the number of trees that are chosen is the number at which the cross-validation error plateaus.\n",
    "\n",
    "As there are a variety of supervised classification algorithms, in the following we apply a few to a test data set in order to distinguish quasars from stars in a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "#   The figure produced by this code is published in the textbook\n",
    "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
    "#   For more information, see http://astroML.github.com\n",
    "#   To report a bug or issue, use the following forum:\n",
    "#    https://groups.google.com/forum/#!forum/astroml-general\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from astroML.utils import split_samples\n",
    "from astroML.utils import completeness_contamination\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis,\n",
    "                                           QuadraticDiscriminantAnalysis)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from astroML.classification import GMMBayes\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
    "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
    "# result in an error if LaTeX is not installed on your system.  In that case,\n",
    "# you can set usetex to False.\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=10, usetex=True)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Fetch data and split into training and test samples\n",
    "from astroML.datasets import fetch_dr7_quasar\n",
    "from astroML.datasets import fetch_sdss_sspp\n",
    "\n",
    "quasars = fetch_dr7_quasar()\n",
    "stars = fetch_sdss_sspp()\n",
    "\n",
    "# Truncate data for speed\n",
    "quasars = quasars[::5]\n",
    "stars = stars[::5]\n",
    "\n",
    "# stack colors into matrix X\n",
    "Nqso = len(quasars)\n",
    "Nstars = len(stars)\n",
    "X = np.empty((Nqso + Nstars, 4), dtype=float)\n",
    "\n",
    "X[:Nqso, 0] = quasars['mag_u'] - quasars['mag_g']\n",
    "X[:Nqso, 1] = quasars['mag_g'] - quasars['mag_r']\n",
    "X[:Nqso, 2] = quasars['mag_r'] - quasars['mag_i']\n",
    "X[:Nqso, 3] = quasars['mag_i'] - quasars['mag_z']\n",
    "\n",
    "X[Nqso:, 0] = stars['upsf'] - stars['gpsf']\n",
    "X[Nqso:, 1] = stars['gpsf'] - stars['rpsf']\n",
    "X[Nqso:, 2] = stars['rpsf'] - stars['ipsf']\n",
    "X[Nqso:, 3] = stars['ipsf'] - stars['zpsf']\n",
    "\n",
    "y = np.zeros(Nqso + Nstars, dtype=int)\n",
    "y[:Nqso] = 1\n",
    "\n",
    "# split into training and test sets\n",
    "(X_train, X_test), (y_train, y_test) = split_samples(X, y, [0.9, 0.1],\n",
    "                                                     random_state=0)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Compute fits for all the classifiers\n",
    "def compute_results(*args):\n",
    "    names = []\n",
    "    probs = []\n",
    "\n",
    "    for classifier, kwargs in args:\n",
    "        print(classifier.__name__)\n",
    "        model = classifier(**kwargs)\n",
    "        model.fit(X, y)\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "\n",
    "        names.append(classifier.__name__)\n",
    "        probs.append(y_prob[:, 1])\n",
    "\n",
    "    return names, probs\n",
    "\n",
    "LRclass_weight = dict([(i, np.sum(y_train == i)) for i in (0, 1)])\n",
    "\n",
    "names, probs = compute_results((GaussianNB, {}),\n",
    "                               (LinearDiscriminantAnalysis, {}),\n",
    "                               (QuadraticDiscriminantAnalysis, {}),\n",
    "                               (LogisticRegression,\n",
    "                                dict(class_weight=LRclass_weight)),\n",
    "                               (KNeighborsClassifier,\n",
    "                                dict(n_neighbors=10)),\n",
    "                               (DecisionTreeClassifier,\n",
    "                                dict(random_state=0, max_depth=12,\n",
    "                                     criterion='entropy')))\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot results\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "fig.subplots_adjust(left=0.1, right=0.95, bottom=0.15, top=0.9, wspace=0.25)\n",
    "\n",
    "# First axis shows the data\n",
    "ax1 = fig.add_subplot(131)\n",
    "#im = ax1.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=4,\n",
    "#                 linewidths=0, edgecolors='none',\n",
    "#                 cmap=plt.cm.binary)\n",
    "#ax1.legend ('quasars', 'stars')\n",
    "\n",
    "\n",
    "ax1.scatter(X_test[:, 0][y_test==0], X_test[:, 1][y_test==0], c='grey', s=4,\n",
    "                 linewidths=0, edgecolors='none', label='stars')\n",
    "ax1.scatter(X_test[:, 0][y_test==1], X_test[:, 1][y_test==1], c='k', s=4,\n",
    "                 linewidths=0, edgecolors='none',label='quasars')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_xlim(-0.5, 3.0)\n",
    "ax1.set_ylim(-0.3, 1.4)\n",
    "ax1.set_xlabel('$u - g$')\n",
    "ax1.set_ylabel('$g - r$')\n",
    "\n",
    "labels = dict(GaussianNB='GNB',\n",
    "              LinearDiscriminantAnalysis='LDA',\n",
    "              QuadraticDiscriminantAnalysis='QDA',\n",
    "              KNeighborsClassifier='KNN',\n",
    "              DecisionTreeClassifier='DT',\n",
    "              LogisticRegression='LR')\n",
    "\n",
    "# Second axis shows the ROC curves\n",
    "ax2 = fig.add_subplot(132)\n",
    "for name, y_prob in zip(names, probs):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "    fpr = np.concatenate([[0], fpr])\n",
    "    tpr = np.concatenate([[0], tpr])\n",
    "    \n",
    "    ax2.plot(fpr, tpr, label=labels[name])\n",
    "    \n",
    "    ######\n",
    "    \n",
    "# Third axis shows the completeness-efficiency curves\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "for name, y_prob in zip(names, probs):\n",
    "    comp = np.zeros_like(thresholds)\n",
    "    cont = np.zeros_like(thresholds)\n",
    "    for i, t in enumerate(thresholds):\n",
    "        y_pred = (y_prob >= t)\n",
    "        comp[i], cont[i] = completeness_contamination(y_pred, y_test)\n",
    "    ax3.plot(comp,1 - cont, label=labels[name])\n",
    "    \n",
    "\n",
    "ax2.legend(loc=4)\n",
    "ax2.set_title('ROC curves')\n",
    "ax2.set_xlabel('false positive rate')\n",
    "ax2.set_ylabel('true positive rate')\n",
    "ax2.set_xlim(0, 0.15)\n",
    "ax2.set_ylim(0.6, 1.01)\n",
    "ax2.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "\n",
    "ax3.set_title('completeness-efficiency curves')\n",
    "ax3.set_xlabel('efficiency')\n",
    "ax3.set_ylabel('completeness')\n",
    "ax3.set_xlim(0, 1.0)\n",
    "ax3.set_ylim(0.2, 1.02)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see two **diagnostic plots** (see also lecture slides 5).\n",
    "\n",
    "A receiver operating characteristic curve, or **ROC curve**, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. \n",
    "\n",
    "\n",
    "One concern about ROC curves is that they are sensitive to the relative\n",
    "sample sizes: if there are many more background events than source\n",
    "events, small false positive results can dominate a signal.\n",
    "For these cases we can plot completeness versus efficiency.\n",
    "\n",
    "\n",
    "\n",
    "Here we see that to get higher completeness, you could actually suffer significantly in terms of efficiency, but your false positive rate (FPR) might not go up that much if there are lots of true negatives.\n",
    "Note that the desired completeness and efficiency is chosen by selecting a decision boundary. The curves show what these possible choices are. Generally, one wants to chose a decision boundary that **maximizes the area\n",
    "under the** ROC (or completeness versus efficiency) **curve**.\n",
    "\n",
    "\n",
    "remember: we defined\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "{\\rm completeness} = \\frac{\\rm true\\ positives}{\\rm true\\ positives + false\\ negatives}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*} \n",
    "{\\rm contamination} = \\frac{\\rm false\\ positives}{\\rm true\\ positives + false\\ positives} = {\\rm false\\ discovery\\ rate}\n",
    "\\end{equation*}\n",
    "\n",
    "Instead of contamination, often also efficiency (also called purity) is used: ${\\rm efficiency} = \\rm{(1 - contamination)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Supervised Classification - Multiclass Classifiers <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "\n",
    "\n",
    "In many cases we not only want to discriminate between two classes, but many. This is called a **multiclass classifier**. That's exactly what we need for the TESS data.\n",
    "In the following, you will see a complete example using the `iris` test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the data set from the original iris data set to look more like a typical astronomical data set\n",
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#replace target with names like usually found in astronomical data sets\n",
    "target_names = target.replace([0, 1, 2], ['setosa', 'versicolor', 'virginica'])\n",
    "\n",
    "dataset = pd.concat([data,target_names.reindex(data.index)], axis=1)\n",
    "\n",
    "\n",
    "#Renaming the columns\n",
    "dataset.columns = ['sepal length in cm', 'sepal width in cm','petal length in cm','petal width in cm','species']\n",
    "print('Shape of the dataset: ' + str(data.shape))\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "\n",
    "# we now have our data set, like we have read it from a cvs text file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the dependent variable class**\n",
    "\n",
    "We are converting species column values from ['Iris-setosa','Iris-versicolor','Iris-virginica'] to [0,1,2]. This is an essential step as the scikit-learn's Random Forest can't predict text — it can only predict numbers.\n",
    "\n",
    "Yes, we had just converted it from numbers to text labels... This was done to mimic we were reading in a typical text file.\n",
    "\n",
    "In addition, we need to store the factor conversions to remember what number is substituting the text.\n",
    "The code below will perform the following:\n",
    "\n",
    " *   Use `pandas` factorize function to factorize the species column in the dataset. This will create both factors and the definitions for the factors.\n",
    " *   Store the factorized column as species.\n",
    " *   Store the definitions for the factors.\n",
    " *   Show the first five rows for the species column and the defintions array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(dataset['species'])\n",
    "dataset.species = factor[0]\n",
    "definitions = factor[1]\n",
    "print(dataset.species.head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X = dataset.iloc[:,0:4].values\n",
    "y = dataset.iloc[:,4].values\n",
    "print('The independent features set: ')\n",
    "print(X[:5,:])\n",
    "print('The dependent variable: ')\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Test Data Splitting**\n",
    "\n",
    "We will use 75% of the data for training and the remaining 25% as test data (i.e., 75% of 150 rows as 112 rows for training and 38 rows for testing). \n",
    "\n",
    "Also, the reason for such high number of test case percentages is due to fewer numbers of rows for the model. Generally, 80/20 rule for train-test is used when data is sufficiently high.\n",
    "\n",
    "The below code uses the prebuilt function 'train_test_split' in a sklearn library for creating the train and test arrays for both independent and dependent variable. Also, random_state = 21 is assigned for random distribution of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling**\n",
    "\n",
    "This is a very important step in machine learning. It helps the algorithm quickly learn a better solution to the problem.\n",
    "\n",
    "We will use a standard scaler provided in the sklearn library. It subtracts the mean value of the observation and then divides it by the unit variance of the observation.\n",
    "We will perform the following steps:\n",
    "\n",
    "    Define a scaler by calling the function from sklearn library.\n",
    "    Transform train feature dataset (X_train) and fit the scaler on train feature dataset.\n",
    "    Use the scaler to transform test feature dataset (X_test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**\n",
    "\n",
    "We define the parameters for the random forest training as follows:\n",
    "\n",
    "    n_estimators: This is the number of trees in the random forest classification. We have defined 10 trees in our random forest.\n",
    "    criterion: This is the loss function used to measure the quality of the split. There are two available options in sklearn — gini and entropy. We have used entropy.\n",
    "    random_state: This is the seed used by the random state generator for randomizing the dataset.\n",
    "\n",
    "Next, we use the training dataset (both dependent and independent to train the random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the performance**\n",
    "\n",
    "Performance evaluation of the trained model consists of following steps:\n",
    "\n",
    "    Predicting the species class of the test data using test feature set (X_test). We will use the predict function of the random forest classifier to predict classes.\n",
    "    Converting the numeric classes of the predicted values and the test actual values into textual equivalent. This involves the following steps:\n",
    "        Creating dictionary for mapping tables from class to text — we use dict function along with zip to create the required dictionary.\n",
    "        Transforming the test-actual and test-predict database from numeric classes to textual classes.\n",
    "        Evaluating the performance of the classifier using Confusion Matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to Iris-setosa, Iris-versicolor and Iris-virginica\n",
    "reversefactor = dict(zip(range(3),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Species'], colnames=['Predicted Species']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(dataset.columns[0:4], classifier.feature_importances_)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 10-fold verification <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "\n",
    "\n",
    "In the example above we saw how to split the initial data set into a training and testing data set.\n",
    "Whereas this can be done as a first step, it is highly recommended using **10-fold verification**, where in turn 10 % of the data are held out as a test set and 90 % are used for training.\n",
    "\n",
    "In the following, we will implement this in the same way as the example above, using the `iris`data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "#create the data set from the original iris data set to look more like a typical astronomical data set\n",
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#replace target with names like usually found in astronomical data sets\n",
    "target_names = target.replace([0, 1, 2], ['setosa', 'versicolor', 'virginica'])\n",
    "\n",
    "dataset = pd.concat([data,target_names.reindex(data.index)], axis=1)\n",
    "\n",
    "\n",
    "#Renaming the columns\n",
    "dataset.columns = ['sepal length in cm', 'sepal width in cm','petal length in cm','petal width in cm','species']\n",
    "print('Shape of the dataset: ' + str(data.shape))\n",
    "\n",
    "\n",
    "# we now have our data set, like we have read it from a cvs text file\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "\n",
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(dataset['species'])\n",
    "dataset.species = factor[0]\n",
    "definitions = factor[1]\n",
    "print(dataset.species.head())\n",
    "print(definitions)\n",
    "\n",
    "#Splitting the data into independent and dependent variables\n",
    "X = dataset.iloc[:,0:4].values\n",
    "y = dataset.iloc[:,4].values\n",
    "print('The independent features set: ')\n",
    "print(X[:5,:])\n",
    "print('The dependent variable: ')\n",
    "print(y[:5])\n",
    "\n",
    "\n",
    "folds = 10\n",
    "k_fold = KFold(folds, shuffle=True, random_state=1)\n",
    "\n",
    "predicted_targets = np.array([])\n",
    "actual_targets = np.array([])\n",
    "\n",
    "\n",
    "input_folds = np.empty(folds, dtype=object)\n",
    "result_folds = np.empty(folds, dtype=object)\n",
    "\n",
    "fold=0\n",
    "\n",
    "for train_ix, test_ix in k_fold.split(X):\n",
    "        train_x, train_y, test_x, test_y = X[train_ix], y[train_ix], X[test_ix], y[test_ix]\n",
    "        \n",
    "        \n",
    "        print('X size: ', X.size)\n",
    "        print('test_x size: ', test_x.size)\n",
    "\n",
    "        # Fit the classifier\n",
    "       # classifier = svm.SVC().fit(train_x, train_y)\n",
    "    \n",
    "        # Feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        train_x = scaler.fit_transform(train_x)\n",
    "        test_x = scaler.transform(test_x)\n",
    "    \n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "        classifier.fit(train_x, train_y)\n",
    "\n",
    "        # Predict the labels of the test set samples\n",
    "        predicted_labels = classifier.predict(test_x)\n",
    "\n",
    "        predicted_targets = np.append(predicted_targets, predicted_labels)\n",
    "        actual_targets = np.append(actual_targets, test_y)\n",
    "        \n",
    "        \n",
    "        # instead, save predicted, actual in 2d matrix\n",
    "        input_folds[fold] = test_y\n",
    "        result_folds[fold] = predicted_labels\n",
    "        \n",
    "        fold=fold+1\n",
    "        \n",
    "\n",
    "print('actual')        \n",
    "print(actual_targets)  \n",
    "print('predicted')        \n",
    "print(predicted_targets)       \n",
    "\n",
    "print('input_folds')        \n",
    "print(input_folds)\n",
    "print('result_folds')        \n",
    "print(result_folds)\n",
    "        \n",
    "        \n",
    "cnf_matrix = confusion_matrix(actual_targets, predicted_targets)\n",
    "\n",
    "\n",
    "print(cnf_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# here we calculate the scores for all three classes to report the classifier performance\n",
    "\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "print('TPR')\n",
    "print(TPR)\n",
    "\n",
    "print('FPR')\n",
    "print(FPR)\n",
    "\n",
    "print('ACC')\n",
    "print(ACC)\n",
    "\n",
    "\n",
    "# reuse plotting code from notebook 5\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def to_density(cf):\n",
    "  '''\n",
    "  This function will take in a confusion matrix cf and return the relative 'density' of every element in each row.\n",
    "  ---------\n",
    "  cf: Confusion matrix to be passed in\n",
    "  '''\n",
    "  density = []\n",
    "  n, k = cf.shape\n",
    "  for i in range(n):\n",
    "    density_row = []\n",
    "    for j in range(k):\n",
    "      total_stars = sum(cf[i])\n",
    "      density_row.append(cf[i][j]/total_stars)\n",
    "    density.append(density_row)\n",
    "  return np.array(density)\n",
    "\n",
    "\n",
    "def make_confusion_matrix(cf_,\n",
    "                          xlabel, ylabel,\n",
    "                          group_names=None,\n",
    "                          categories_x='auto',\n",
    "                          categories_y='auto',\n",
    "                          count=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None,\n",
    "                          ):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf_:            Confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "    cf = to_density(cf_)\n",
    "    \n",
    "    # Generate the labels for the matrix elements:\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.2f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_labels,group_counts)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # Set figure paramaters:\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # Make the heatmap:\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,yticklabels=categories_y,xticklabels=categories_x)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel(xlabel)\n",
    "        plt.xlabel(ylabel)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "        \n",
    "\n",
    "# Make a confusion matrix plot for 10-fold cross-validation:\n",
    "\n",
    "make_confusion_matrix(cnf_matrix, xlabel='predicted', ylabel='true',categories_x=iris.target_names,categories_y=iris.target_names, count=True, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your tasks until next week:**\n",
    "\n",
    "Based on what you have seen here: Use a multiclass supervised machine learning algorithm on the three TESS feature data sets, including making diagnostic plots and the classification scores.\n",
    "\n",
    "Hint: Use the `scikit-learn` documentation (a good starting point: https://scikit-learn.org/stable/modules/multiclass.html). You can also generally search for code examples and reuse parts of the code. Reusing code is a great way to learn. As always: When reusing code, never use this without understanding what the code does!\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Processing Pipelines <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "\n",
    "We already have seen *data processing pipelines* to some extent:\n",
    "\n",
    "* TESS light-curve data were first detrended and outlier-cleaned: _TESS_lightcurves_raw $\\rightarrow$ _TESS_lightcurves_median_after_detrended $\\rightarrow$  _TESS_lightcurves_outliercleaned\n",
    "* features were calculated from (outlier-cleaned) TESS light-curve data\n",
    "* features were used for classification\n",
    "\n",
    "**Question:** \n",
    "Can you think of ways to improve the classification process?\n",
    "What does \"improve\" exactly mean? What we want to achieve?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large existing and upcoming surveys, such as LSST, rely and will rely heavily on data processing pipelines, e.g. for LSST:\n",
    "    \n",
    "    \n",
    "https://www.lsst.org/about/dm/pipelines\n",
    "\n",
    "https://antares.noirlab.edu/pipeline\n",
    "    \n",
    "Such surveys have the goal to:\n",
    "\n",
    "* find \"unknowns\", \"unknown unknowns\"\n",
    "* find more examples of the same types to build catalogs.\n",
    "    \n",
    "**Question:**\n",
    "How is this related to the science you are doing currently, and/or are planning to do?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "\n",
    "At this point, all of you should have:\n",
    "\n",
    "\n",
    "* seen how `scikit-learn` works in general\n",
    "* seen some complete examples of machine learning for both unsupervised and supervised classification in the case of binary and multiclass classification\n",
    "* seen ways on how to verify machine learning results for both unsupervised and supervised classification in the case of binary and multiclass classification.\n",
    "* seen how machine learning, and data processing pipelines in general, fit into the larger picture in processing astronomical data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
